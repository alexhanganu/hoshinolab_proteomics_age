{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ssp/Dropbox/github/nimb/nimb\n",
      "        credentials are located at: /home/ssp/nimb\n",
      "        credentials are located at: /home/ssp/nimb\n"
     ]
    }
   ],
   "source": [
    "project      = 'hoshinolab_proteomics_age'\n",
    "from bin import nimb_link\n",
    "NIMB_HOME = nimb_link.link_with_nimb()\n",
    "from setup.get_vars import Get_Vars, SetProject\n",
    "from distribution import utilities as utils\n",
    "from stats.db_processing import Table\n",
    "from stats.preprocessing import Preprocess\n",
    "from stats import preprocessing, varia\n",
    "from stats.make_stats_grid import MakeGrid\n",
    "from stats.stats_models import ANOVA_do\n",
    "from stats.plotting import Make_Plot_Regression, Make_plot_group_difference\n",
    "from stats import predict\n",
    "tab = Table()\n",
    "\n",
    "all_vars = Get_Vars()\n",
    "project_vars = all_vars.projects[project]\n",
    "\n",
    "getvars      = Get_Vars()\n",
    "nimb_stats   = getvars.stats_vars\n",
    "projects     = getvars.projects\n",
    "NIMB_tmp     = getvars.location_vars['local']['NIMB_PATHS']['NIMB_tmp']\n",
    "fname_groups = projects[project][\"fname_groups\"]\n",
    "nimb_stats   = SetProject(NIMB_tmp, nimb_stats, project, fname_groups).stats\n",
    "project_vars = projects[project]\n",
    "stats_paths  = nimb_stats['STATS_PATHS']\n",
    "vars_glm     = project_vars['variables_for_glm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    reading file: /media/g/nimb_tmp/projects/hoshinolab_proteomics_age/stats_src/stats/stats_src.xlsx,\n",
      "        sheet: 0\n",
      "    reading file: /media/g/nimb_tmp/projects/hoshinolab_proteomics_age/stats_src/stats/grid.csv,\n",
      "        sheet: 0\n"
     ]
    }
   ],
   "source": [
    "df_user_stats, df_final_grid,\\\n",
    "            df_adjusted,\\\n",
    "            cols_X,\\\n",
    "            groups = MakeGrid(project_vars,\n",
    "                                nimb_stats).grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this grid has an error, as the former index is being saved as a column and must be removed\n",
    "col2rm = 'Unnamed: 0'\n",
    "df_final_grid.drop(columns=[col2rm], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some cols have zeros and because of them ANOVA cannot be performed.\n",
    "# this step removes the columns with at least 1 zero\n",
    "\n",
    "cols_with_zeros = list()\n",
    "for col in df_final_grid.columns:\n",
    "    n = df_final_grid[col].isin([0]).sum()\n",
    "    if n>0:\n",
    "        cols_with_zeros.append(col)\n",
    "#(df_final_grid == 0).astype(int).sum(axis=0)\n",
    "#(df_final_grid == 0).sum(axis=1)\n",
    "\n",
    "df_final_grid.drop(columns=cols_with_zeros, inplace=True)\n",
    "features = [i for i in cols_X if i not in cols_with_zeros+[col2rm,]]\n",
    "vars_glm = features#[i for i in vars_glm if i not in cols_with_zeros+[col2rm,]]\n",
    "\n",
    "# for ANOVA zeros must be removed\n",
    "\n",
    "sig_cols = ANOVA_do(df_final_grid,\n",
    "                    vars_glm, features,\n",
    "                    varia.get_dir(stats_paths['anova']),\n",
    "                    p_thresh = 0.05, intercept_thresh = 0.05).sig_cols\n",
    "Make_Plot_Regression(df_final_grid,\n",
    "                    sig_cols, project_vars['group_col'],\n",
    "                    varia.get_dir(stats_paths['simp_lin_reg_dir']))\n",
    "#Make_plot_group_difference(df_final_grid,\n",
    "#                            sig_cols, project_vars['group_col'], groups,\n",
    "#                            varia.get_dir(stats_paths['anova']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting features based on PCA\n",
    "def get_X_data_per_group_all_groups(group):\n",
    "    # extract X_scaled values for the brain parameters\n",
    "        predicted_target = project_vars[\"prediction_target\"]\n",
    "        if not predicted_target:\n",
    "            predicted_target = project_vars[\"group_col\"]\n",
    "        if group == 'all':\n",
    "                df_clin_group = df_user_stats\n",
    "                df_X          = df_adjusted\n",
    "                y_labeled     = preprocessing.label_y(df_user_stats, predicted_target)\n",
    "                X_scaled      = preprocessing.scale_X(df_X)\n",
    "        else:\n",
    "                df_group      = tab.get_df_per_parameter(df_final_grid, project_vars['group_col'], group)\n",
    "                df_clin_group = tab.rm_cols_from_df(df_group, cols_X)\n",
    "                df_X          = tab.rm_cols_from_df(df_group, [i for i in df_group.columns.tolist() if i not in cols_X])\n",
    "                y_labeled     = preprocessing.label_y(df_group, predicted_target)\n",
    "                X_scaled      = preprocessing.scale_X(df_X)\n",
    "        return df_X, y_labeled, X_scaled, df_clin_group\n",
    "    \n",
    "def get_features_df_per_group(group, X_scaled, y_labeled, df_X):\n",
    "        features_rfe_and_rank_df = 'none'\n",
    "        if self.use_features:\n",
    "            if self.feature_algo == 'PCA':# using PCA\n",
    "                    features = predict.get_features_based_on_pca(varia.get_dir(path.join(self.stats_paths['STATS_HOME'], self.stats_paths['features'])),\n",
    "                                                        self.prediction_vars['pca_threshold'],\n",
    "                                                        X_scaled, self.cols_X,\n",
    "                                                        group, self.atlas)\n",
    "            elif self.feature_algo == 'RFE': # using RFE\n",
    "                    features, features_rfe_and_rank_df = predict.feature_ranking(X_scaled,\n",
    "                                                                        y_labeled,\n",
    "                                                                        self.cols_X)\n",
    "                    print(\"    number of features extracted by RFE: \",len(features_rfe_and_rank_df.feature))\n",
    "            df_with_features = self.tab.get_df_from_df(df_X, usecols = features)\n",
    "        else:\n",
    "            df_with_features = self.tab.get_df_from_df(df_X, usecols = self.cols_X)\n",
    "            features = self.cols_X\n",
    "        return df_with_features, features, features_rfe_and_rank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PowerTransformer()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssp/.local/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:3234: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    }
   ],
   "source": [
    "group = 'all'\n",
    "df_X, y_labeled, X_scaled, df_clin_group = get_X_data_per_group_all_groups(group)\n",
    "features = cols_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = Preprocess(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script executing.....\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
